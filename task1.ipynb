{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='grid_search.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "class LoggingCallback:\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        logging.info('GridSearchCV: {}'.format(kwargs.get('msg', '')))\n",
    "\n",
    "class WindowRandomForest:\n",
    "    def __init__(self, n_list, n_estimators=100, random_state=42):\n",
    "        if not all(n % 2 != 0 for n in n_list):\n",
    "            raise ValueError(\"All values in n_list must be odd numbers.\")\n",
    "        self.n_list = n_list\n",
    "        self.model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.random_state = random_state\n",
    "        random.seed(self.random_state)\n",
    "        print(\"Initialized WindowRandomForest with n_list:\", n_list)\n",
    "\n",
    "    def prepare_data(self, data, random_seed=None):\n",
    "        if random_seed is not None:\n",
    "            random.seed(random_seed)\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        i = 0\n",
    "        data_len = len(data)\n",
    "        min_window = min(self.n_list)\n",
    "        \n",
    "        print(\"Preparing data...\")\n",
    "        while i <= data_len - min_window:\n",
    "            current_n = random.choice(self.n_list)\n",
    "            if i + current_n > data_len:\n",
    "                break\n",
    "            \n",
    "            window = data.iloc[i:i+current_n, :-1]\n",
    "            label_window = data.iloc[i:i+current_n, -1]\n",
    "            \n",
    "            majority_label = mode(label_window)[0]\n",
    "            aggregated_features = self.aggregate_features(window)\n",
    "            \n",
    "            X.append(aggregated_features)\n",
    "            y.append(majority_label)\n",
    "            \n",
    "            i += current_n\n",
    "    \n",
    "        print(f\"Prepared {len(X)} windows.\")\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def aggregate_features(self, window):\n",
    "        #print(\"Aggregating features for window of size:\", len(window))\n",
    "        return window.mean(axis=0)\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        print(\"Fitting model...\")\n",
    "        X, y = self.prepare_data(train_data)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val = self.scaler.transform(X_val)\n",
    "\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'bootstrap': [True, False]\n",
    "        }\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=self.model, param_grid=param_grid, cv=10, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train, y_train, callbacks=[LoggingCallback()])\n",
    "\n",
    "        self.model = grid_search.best_estimator_\n",
    "        print(\"Best parameters found by GridSearchCV:\", grid_search.best_params_)\n",
    "\n",
    "        y_val_pred = []\n",
    "        y_val_pred_proba = []\n",
    "\n",
    "        for row in X_val:\n",
    "            y_val_pred.append(self.predict_single_row(row))\n",
    "            y_val_pred_proba.append(self.model.predict_proba(self.scaler.transform(row.reshape(1, -1)))[0][1])\n",
    "        \n",
    "        print('Validation Classification Report:')\n",
    "        print(classification_report(y_val, y_val_pred))\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_val, y_val_pred_proba)\n",
    "        print(f'ROC AUC Score: {roc_auc}')\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_val_pred_proba)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        print(\"Evaluating model...\")\n",
    "        X_test, y_test = self.prepare_data(test_data)\n",
    "\n",
    "        y_test_pred = []\n",
    "        y_test_pred_proba = []\n",
    "\n",
    "        for row in X_test:\n",
    "            y_test_pred.append(self.predict_single_row(row))\n",
    "            y_test_pred_proba.append(self.model.predict_proba(self.scaler.transform(row.reshape(1, -1)))[0][1])\n",
    "        \n",
    "        print('Test Classification Report:')\n",
    "        print(classification_report(y_test, y_test_pred))\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "        print(f'ROC AUC Score: {roc_auc}')\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, data, row_index):\n",
    "        if row_index < min(self.n_list) - 1:\n",
    "            raise ValueError(f\"Not enough data to form a window of {min(self.n_list)} rows for prediction.\")\n",
    "        \n",
    "        window = data.iloc[row_index-(min(self.n_list)-1):row_index+1, :-1]\n",
    "        aggregated_features = self.aggregate_features(window)\n",
    "        \n",
    "        aggregated_features = self.scaler.transform([aggregated_features])\n",
    "        prediction = self.model.predict(aggregated_features)\n",
    "        return prediction[0]\n",
    "\n",
    "    def predict_single_row(self, row):\n",
    "        row = self.scaler.transform(row.reshape(1, -1))\n",
    "        return self.model.predict(row)[0]\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        joblib.dump({\n",
    "            'model': self.model,\n",
    "            'scaler': self.scaler,\n",
    "            'n_list': self.n_list\n",
    "        }, model_path)\n",
    "        print(f'Model saved to {model_path}')\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        saved_objects = joblib.load(model_path)\n",
    "        self.model = saved_objects['model']\n",
    "        self.scaler = saved_objects['scaler']\n",
    "        self.n_list = saved_objects['n_list']\n",
    "        print(f'Model loaded from {model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized WindowRandomForest with n_list: [1, 3, 5, 7, 9]\n",
      "Fitting model...\n",
      "Preparing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2160 [02:23<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 92693 windows.\n",
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 2160 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2160 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\nTypeError: BaseForest.fit() got an unexpected keyword argument 'callbacks'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m wrf \u001b[38;5;241m=\u001b[39m WindowRandomForest(n_list)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mwrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     11\u001b[0m wrf\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mWindowRandomForest.fit\u001b[1;34m(self, train_data)\u001b[0m\n\u001b[0;32m     75\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m     81\u001b[0m }\n\u001b[0;32m     83\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mLoggingCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found by GridSearchCV:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:945\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    941\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    943\u001b[0m     )\n\u001b[1;32m--> 945\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 2160 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2160 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\KARAN\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\nTypeError: BaseForest.fit() got an unexpected keyword argument 'callbacks'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Normal_Abnormal_eval_0.2_Eval_1sec_hamming.csv')\n",
    "\n",
    "n_list = [1,3, 5, 7, 9] \n",
    "wrf = WindowRandomForest(n_list)\n",
    "\n",
    "# Train the model\n",
    "wrf.fit(df)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "wrf.evaluate()\n",
    "\n",
    "# Save the model to a file\n",
    "model_path = 'wrf_model.pkl'\n",
    "wrf.save_model(model_path)\n",
    "\n",
    "# Create a new instance of the model\n",
    "wrf_loaded = WindowRandomForest(n=n)\n",
    "\n",
    "# Load the model from the file\n",
    "wrf_loaded.load_model(model_path)\n",
    "\n",
    "single_row_index = 1  \n",
    "single_row = df.iloc[single_row_index, :-1].values \n",
    "\n",
    "predicted_label = wrf_loaded.predict_single_row(single_row)\n",
    "print(f'Predicted Label for row {single_row_index}: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
